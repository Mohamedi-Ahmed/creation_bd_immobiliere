{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres de connexion MySQL\n",
    "user = os.getenv('DB_USER')\n",
    "password = os.getenv('DB_PASSWORD')\n",
    "host = os.getenv('DB_HOST')\n",
    "database = os.getenv('DB_NAME')\n",
    "\n",
    "engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}/{database}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valeurs foncieres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Chargement du fichier excel\n",
    "valeurs_foncieres = pd.read_excel(\"../data/valeurs_foncieres.xlsx\")\n",
    "\n",
    "# Nettoyage des noms de colonnes\n",
    "valeurs_foncieres.columns = valeurs_foncieres.columns.str.strip()\n",
    "valeurs_foncieres.columns = valeurs_foncieres.columns.str.lower()\n",
    "valeurs_foncieres.columns = valeurs_foncieres.columns.str.replace(' ', '_')\n",
    "\n",
    "valeurs_foncieres = valeurs_foncieres[['identifiant_local', 'date_mutation', 'valeur_fonciere', 'no_voie',\n",
    "                                       'type_de_voie', 'voie', 'nombre_pieces_principales', 'surface_reelle_bati',\n",
    "                                       'surface_carrez_du_1er_lot', 'type_local', 'code_commune']].copy()\n",
    "\n",
    "# Renommer pour se coller au schema\n",
    "valeurs_foncieres.rename(columns={\n",
    "    'identifiant_local': 'id_bien',\n",
    "    'date_mutation': 'date',\n",
    "    'valeur_fonciere': 'valeur',\n",
    "    'no_voie': 'no_voie',\n",
    "    'type_de_voie': 'type_voie',\n",
    "    'voie': 'voie',\n",
    "    'nombre_pieces_principales': 'total_piece',\n",
    "    'surface_reelle_bati': 'surface_local',\n",
    "    'surface_carrez_du_1er_lot': 'surface_carrez',\n",
    "    'type_local': 'type_local',\n",
    "    'code_commune': 'id_commune'\n",
    "}, inplace=True)\n",
    "\n",
    "# Problème de fichier => identifiant_local nul\n",
    "valeurs_foncieres['id_bien'] = range(1, len(valeurs_foncieres) + 1)\n",
    "\n",
    "\n",
    "# Convertir la date et filtrer le 1er semestre 2020 pour respecter le compte-rendu de réunion de validation\n",
    "valeurs_foncieres['date'] = pd.to_datetime(valeurs_foncieres['date'], errors='coerce')\n",
    "valeurs_foncieres = valeurs_foncieres[valeurs_foncieres['date'].dt.year == 2020]\n",
    "valeurs_foncieres = valeurs_foncieres[valeurs_foncieres['date'].dt.month <= 6]\n",
    "\n",
    "# Remplacement des valeurs manquantes\n",
    "valeurs_foncieres['surface_local'] = valeurs_foncieres['surface_local'].fillna(0)\n",
    "valeurs_foncieres['total_piece'] = valeurs_foncieres['total_piece'].fillna(0)\n",
    "valeurs_foncieres['surface_carrez'] = valeurs_foncieres['surface_carrez'].fillna(0)\n",
    "valeurs_foncieres['type_voie'] = valeurs_foncieres['type_voie'].fillna('INCONNU')\n",
    "valeurs_foncieres['voie'] = valeurs_foncieres['voie'].fillna('INCONNU')\n",
    "valeurs_foncieres['type_local'] = valeurs_foncieres['type_local'].fillna('INCONNU')\n",
    "\n",
    "valeurs_foncieres.dropna(subset=['date', 'valeur', 'id_commune'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regions + Communes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_list = [\n",
    "    \"Auvergne-Rhône-Alpes\",\n",
    "    \"Bourgogne-Franche-Comté\",\n",
    "    \"Bretagne\",\n",
    "    \"Centre-Val de Loire\",\n",
    "    \"Corse\",\n",
    "    \"Grand Est\",\n",
    "    \"Hauts-de-France\",\n",
    "    \"Île-de-France\",\n",
    "    \"Normandie\",\n",
    "    \"Nouvelle-Aquitaine\",\n",
    "    \"Pays de la Loire\",\n",
    "    \"Provence-Alpes-Côte d'Azur\",\n",
    "    \"La Réunion\"\n",
    "]\n",
    "\n",
    "regions_df = pd.DataFrame({'nom_region': regions_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du fichier excel\n",
    "communes = pd.read_excel(\"../data/donnees_communes.xlsx\")\n",
    "\n",
    "communes.columns = communes.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "\n",
    "# Corriger les problèmes d'encodage des noms de régions\n",
    "communes['reg'] = communes['reg'].apply(lambda x: x.encode('latin1', errors='ignore').decode('utf-8', errors='ignore') if isinstance(x, str) else x)\n",
    "communes['com'] = communes['com'].apply(lambda x: x.encode('latin1', errors='ignore').decode('utf-8', errors='ignore') if isinstance(x, str) else x)\n",
    "\n",
    "regions_table_df = pd.DataFrame({\n",
    "    'nom_region': [\n",
    "        \"Auvergne-Rhône-Alpes\", \"Bourgogne-Franche-Comté\", \"Bretagne\", \"Centre-Val de Loire\", \"Corse\",\n",
    "        \"Grand Est\", \"Hauts-de-France\", \"Île-de-France\", \"Normandie\", \"Nouvelle-Aquitaine\",\n",
    "        \"Pays de la Loire\", \"Provence-Alpes-Côte d'Azur\", \"La Réunion\"\n",
    "    ],\n",
    "    'id_region': range(1, 14)\n",
    "})\n",
    "\n",
    "# Fusionner les régions sur la base du nom de la région\n",
    "communes = communes.merge(\n",
    "    regions_table_df[['nom_region', 'id_region']],\n",
    "    left_on='reg',\n",
    "    right_on='nom_region',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "communes = communes[['codcom', 'id_region', 'coddep', 'com']].rename(columns={\n",
    "    'codcom': 'id_commune',\n",
    "    'coddep': 'code_departement',\n",
    "    'com': 'nom_commune'\n",
    "})\n",
    "\n",
    "communes = communes.dropna(subset=['id_region'])\n",
    "communes['id_region'] = communes['id_region'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_population_by_dep(code_departement, nom_commune):\n",
    "    url = f\"https://geo.api.gouv.fr/departements/{code_departement}/communes\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # Lève une erreur si la requête a échoué\n",
    "\n",
    "        nom_commune = nom_commune.strip()\n",
    "\n",
    "        data = response.json()\n",
    "        for commune in data:\n",
    "            if str(commune['codeDepartement']) == str(code_departement) and commune['nom'] == nom_commune:\n",
    "                return commune['population']\n",
    "\n",
    "        return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du fichier excel\n",
    "populations = pd.read_excel(\"../data/populations_referentiel_geograpgique.xlsx\")\n",
    "\n",
    "populations.columns = populations.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "populations = populations[['com_code','dep_nom', 'dep_code', 'uucr_nom']].copy()\n",
    "populations.rename(columns={\n",
    "    'com_code': 'id_commune',\n",
    "}, inplace=True)\n",
    "\n",
    "populations['code_departement'] = populations['dep_code']\n",
    "\n",
    "populations['dep_nom'] = populations['dep_nom'].str.encode('utf-8').str.decode('utf-8')\n",
    "populations['dep_nom'] = populations['dep_nom'].apply(lambda x: x.encode('latin1', errors='ignore').decode('utf-8', errors='ignore') if isinstance(x, str) else x)\n",
    "\n",
    "populations['nom_commune'] = populations['uucr_nom'].str.encode('utf-8').str.decode('utf-8')\n",
    "populations['nom_commune'] = populations['nom_commune'].apply(lambda x: x.encode('latin1', errors='ignore').decode('utf-8', errors='ignore') if isinstance(x, str) else x)\n",
    "\n",
    "populations = populations[['id_commune', 'nom_commune','dep_nom', 'code_departement', ]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(disable=True)\n",
    "populations['population'] = populations.progress_apply(\n",
    "    lambda x: get_population_by_dep(x['code_departement'], x['nom_commune']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les données du gouvernement sont issus datées de 2025\n",
    "populations['annee'] = 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = populations.merge(\n",
    "    communes[['id_commune', 'nom_commune']],\n",
    "    how='left',\n",
    "    left_on='nom_commune',\n",
    "    right_on='nom_commune'\n",
    ")\n",
    "\n",
    "populations.drop(columns=['id_commune_x'], inplace=True)\n",
    "populations.rename(columns={'id_commune_y': 'id_commune'}, inplace=True)\n",
    "populations.dropna(subset=['id_commune'], inplace=True)\n",
    "populations['id_commune'] = populations['id_commune'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insertion des données dans la DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début de l'importation des données\n",
      "Données region insérées\n",
      "Données 'commune' insérées\n",
      "Données 'bien' insérées\n",
      "Données 'vente' insérées\n",
      "Données 'population' insérées\n",
      "Importation terminée avec succès\n"
     ]
    }
   ],
   "source": [
    "# Insérer les données dans MySQ\n",
    "print(\"Début de l'importation des données\")\n",
    "\n",
    "# Region\n",
    "regions_df.to_sql('region', con=engine, if_exists='append', index=False)\n",
    "print(\"Données region insérées\")\n",
    "\n",
    "# Commune\n",
    "communes = communes[['id_commune', 'id_region', 'code_departement', 'nom_commune']]\n",
    "communes = communes.drop_duplicates(subset='id_commune')\n",
    "communes.to_sql('commune', con=engine, if_exists='append', index=False)\n",
    "print(\"Données 'commune' insérées\")\n",
    "\n",
    "# Bien\n",
    "biens = valeurs_foncieres[['id_bien', 'no_voie', 'type_voie', 'voie', 'total_piece', 'surface_carrez', 'surface_local', 'type_local', 'id_commune']].drop_duplicates()\n",
    "biens.to_sql(\"bien\", con=engine, if_exists='append', index=False)\n",
    "print(\"Données 'bien' insérées\")\n",
    "\n",
    "# Vente\n",
    "ventes = valeurs_foncieres[['id_bien', 'date', 'valeur']].copy()\n",
    "ventes.dropna(subset=['date', 'valeur'], inplace=True)\n",
    "ventes.to_sql(\"vente\", con=engine, if_exists='append', index=False)\n",
    "print(\"Données 'vente' insérées\")\n",
    "\n",
    "# Population\n",
    "populations = populations[['id_commune', 'annee', 'population']]\n",
    "populations.to_sql(\"population\", con=engine, if_exists='append', index=False)\n",
    "print(\"Données 'population' insérées\")\n",
    "\n",
    "print(\"Importation terminée avec succès\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
